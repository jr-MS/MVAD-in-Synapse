{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "execution_finish_time": null,
              "execution_start_time": null,
              "livy_statement_state": null,
              "queued_time": "2022-02-18T11:48:40.6355059Z",
              "session_id": null,
              "session_start_time": null,
              "spark_pool": null,
              "state": "waiting",
              "statement_id": null
            },
            "text/plain": [
              "StatementMeta(, , , Waiting, )"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# For Spark 3.1\n",
        "%%configure -f\n",
        "{\n",
        "  \"name\": \"synapseml\",\n",
        "  \"conf\": {\n",
        "      \"spark.jars.packages\": \"com.microsoft.azure:synapseml_2.12:0.9.5-13-d1b51517-SNAPSHOT\",\n",
        "      \"spark.jars.repositories\": \"https://mmlspark.azureedge.net/maven\",\n",
        "      \"spark.jars.excludes\": \"org.scala-lang:scala-reflect,org.apache.spark:spark-tags_2.12,org.scalactic:scalactic_2.12,org.scalatest:scalatest_2.12\",\n",
        "      \"spark.yarn.user.classpath.first\": \"true\"\n",
        "  }\n",
        "}\n",
        "# For Spark 3.2\n",
        "# %%configure -f\n",
        "# {\n",
        "#   \"name\": \"synapseml\",\n",
        "#   \"conf\": {\n",
        "#       \"spark.jars.packages\": \" com.microsoft.azure:synapseml_2.12:0.9.5 \",\n",
        "#       \"spark.jars.repositories\": \"https://mmlspark.azureedge.net/maven\",\n",
        "#       \"spark.jars.excludes\": \"org.scala-lang:scala-reflect,org.apache.spark:spark-tags_2.12,org.scalactic:scalactic_2.12,org.scalatest:scalatest_2.12,io.netty:netty-tcnative-boringssl-static\",\n",
        "#       \"spark.yarn.user.classpath.first\": \"true\"\n",
        "#   }\n",
        "# }"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Learning Materials\n",
        "Check out this [recipe](https://nam06.safelinks.protection.outlook.com/?url=https%3A%2F%2Fmicrosoft.github.io%2FSynapseML%2Fdocs%2Fnext%2Ffeatures%2Fcognitive_services%2FCognitiveServices%2520-%2520Multivariate%2520Anomaly%2520Detection%2F&data=04%7C01%7Cjingruhan%40microsoft.com%7Cc75bbca96910426f341308d9f1d5b74f%7C72f988bf86f141af91ab2d7cd011db47%7C0%7C0%7C637806722495462177%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C3000&sdata=dqQ0lQsOJ9H6yOmfDNHwckwYTdoVenDF7HvHquvMJgw%3D&reserved=0) for reference on this tutorial.\n",
        "\n",
        "Check out this [blog](www.aka.ms/mvad-on-spark) to know the workflow of MVAD in Synapse: www.aka.ms/mvad-on-spark."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "# 💾Import modules"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "from synapse.ml.cognitive import *\n",
        "from notebookutils import mssparkutils"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "execution_finish_time": null,
              "execution_start_time": null,
              "livy_statement_state": null,
              "queued_time": "2022-02-18T12:05:55.7148835Z",
              "session_id": null,
              "session_start_time": null,
              "spark_pool": null,
              "state": "waiting",
              "statement_id": null
            },
            "text/plain": [
              "StatementMeta(, , , Waiting, )"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import pyspark\n",
        "from pyspark.sql.functions import col\n",
        "from pyspark.sql.functions import lit\n",
        "from pyspark.sql.types import DoubleType\n",
        "import synapse.ml\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "# 📈Load data into a Spark Dataframe"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "collapsed": false,
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "execution_finish_time": null,
              "execution_start_time": null,
              "livy_statement_state": null,
              "queued_time": "2022-02-18T11:59:18.6209819Z",
              "session_id": null,
              "session_start_time": null,
              "spark_pool": null,
              "state": "waiting",
              "statement_id": null
            },
            "text/plain": [
              "StatementMeta(, , , Waiting, )"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+--------------------+-----------+------------+------------+\n",
            "|           timestamp|   sensor_1|    sensor_2|    sensor_3|\n",
            "+--------------------+-----------+------------+------------+\n",
            "|2021-01-01T00:00:00Z|0.029422617|-0.473649498| -0.19224458|\n",
            "|2021-01-01T00:01:00Z|1.007787393|-1.052367306| 0.262377261|\n",
            "|2021-01-01T00:02:00Z|0.748065889|-0.566472749|-0.072228041|\n",
            "|2021-01-01T00:03:00Z|0.969546005|-0.376075739|   0.1906547|\n",
            "|2021-01-01T00:04:00Z|1.437884759| 0.882075332|-1.007224649|\n",
            "|2021-01-01T00:05:00Z|0.997356244| 0.328516725|-0.428782042|\n",
            "|2021-01-01T00:06:00Z|0.972924733| 0.695607892|-1.139777769|\n",
            "|2021-01-01T00:07:00Z|1.616419945| 0.082182996| 1.447420156|\n",
            "|2021-01-01T00:08:00Z| 0.73030701| 0.534265584| 1.220560838|\n",
            "|2021-01-01T00:09:00Z|1.576517163|-2.579702562|-1.474013466|\n",
            "+--------------------+-----------+------------+------------+\n",
            "only showing top 10 rows"
          ]
        }
      ],
      "source": [
        "\n",
        "df = spark.read.format(\"csv\").option(\"header\", True).load(\"wasbs://mvadcsvdata@sparkdemostorage.blob.core.windows.net/spark-demo-data.csv\")\n",
        "\n",
        "df = df.withColumn(\"sensor_1\", col(\"sensor_1\").cast(DoubleType())) \\\n",
        "    .withColumn(\"sensor_2\", col(\"sensor_2\").cast(DoubleType())) \\\n",
        "    .withColumn(\"sensor_3\", col(\"sensor_3\").cast(DoubleType()))\n",
        "\n",
        "df.show(10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "# 🔧Training\n",
        "## 1. Training preparation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "execution_finish_time": null,
              "execution_start_time": null,
              "livy_statement_state": null,
              "queued_time": "2022-02-18T12:00:16.1124647Z",
              "session_id": null,
              "session_start_time": null,
              "spark_pool": null,
              "state": "waiting",
              "statement_id": null
            },
            "text/plain": [
              "StatementMeta(, , , Waiting, )"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "#Input your key vault name and anomaly key name in key vault.\n",
        "anomalyKey = mssparkutils.credentials.getSecret(\"[key_vault_name]\",\"[anomaly_key_secret_name]\")\n",
        "#Input your key vault name and connection string name in key vault.\n",
        "connectionString = mssparkutils.credentials.getSecret(\"[key_vault_name]\", \"[connectriong_string_secret_name]\")\n",
        "\n",
        "#Specify information about your data.\n",
        "startTime = \"2021-01-01T00:00:00Z\"\n",
        "endTime = \"2021-01-02T09:18:00Z\"\n",
        "timestampColumn = \"timestamp\"\n",
        "inputColumns = [\"sensor_1\", \"sensor_2\", \"sensor_3\"]\n",
        "#Specify the container you created in Storage account, you could also initialize a new name here, and Synapse will help you create that container automatically.\n",
        "containerName = \"mvadtest\"\n",
        "#Set a folder name in Storage account to store the intermediate data.\n",
        "intermediateSaveDir = \"intermediateData\"\n",
        "\n",
        "simpleMultiAnomalyEstimator = (FitMultivariateAnomaly()\n",
        "    .setSubscriptionKey(anomalyKey)\n",
        "#In .setLocation, use lowercase letter like: eastus.\n",
        "    .setLocation(\"eastus\")\n",
        "    .setStartTime(startTime)\n",
        "    .setEndTime(endTime)\n",
        "    .setContainerName(containerName)\n",
        "    .setIntermediateSaveDir(intermediateSaveDir)\n",
        "    .setTimestampCol(timestampColumn)\n",
        "    .setInputCols(inputColumns)\n",
        "    .setSlidingWindow(200)\n",
        "    .setConnectionString(connectionString))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "## 2. Train a model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "execution_finish_time": null,
              "execution_start_time": null,
              "livy_statement_state": null,
              "queued_time": "2022-02-18T12:00:19.0343766Z",
              "session_id": null,
              "session_start_time": null,
              "spark_pool": null,
              "state": "waiting",
              "statement_id": null
            },
            "text/plain": [
              "StatementMeta(, , , Waiting, )"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "synapse.ml.cognitive.DetectMultivariateAnomaly.DetectMultivariateAnomaly"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "model = simpleMultiAnomalyEstimator.fit(df)\n",
        "type(model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "# 🔍Inference with trained model\n",
        "## 1. Inference"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "collapsed": false,
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "execution_finish_time": null,
              "execution_start_time": null,
              "livy_statement_state": null,
              "queued_time": "2022-02-18T12:05:20.1125868Z",
              "session_id": null,
              "session_start_time": null,
              "spark_pool": null,
              "state": "waiting",
              "statement_id": null
            },
            "text/plain": [
              "StatementMeta(, , , Waiting, )"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "startInferenceTime = \"2021-01-02T09:19:00Z\"\n",
        "endInferenceTime = \"2021-01-03T01:59:00Z\"\n",
        "result = (model\n",
        "      .setStartTime(startInferenceTime)\n",
        "      .setEndTime(endInferenceTime)\n",
        "      .setOutputCol(\"results\")\n",
        "      .setErrorCol(\"errors\")\n",
        "      .setTimestampCol(timestampColumn)\n",
        "      .setInputCols(inputColumns)\n",
        "      .transform(df))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "## 2. Get inference results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "execution_finish_time": null,
              "execution_start_time": null,
              "livy_statement_state": null,
              "queued_time": "2022-02-18T12:06:52.2741757Z",
              "session_id": null,
              "session_start_time": null,
              "spark_pool": null,
              "state": "waiting",
              "statement_id": null
            },
            "text/plain": [
              "StatementMeta(, , , Waiting, )"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>timestamp</th>\n",
              "      <th>sensor_1</th>\n",
              "      <th>sensor_2</th>\n",
              "      <th>sensor_3</th>\n",
              "      <th>isAnomaly</th>\n",
              "      <th>severity</th>\n",
              "      <th>series_0</th>\n",
              "      <th>series_1</th>\n",
              "      <th>series_2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2021-01-02T09:19:00Z</td>\n",
              "      <td>-0.044257</td>\n",
              "      <td>-0.968458</td>\n",
              "      <td>-1.906952</td>\n",
              "      <td>False</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2021-01-02T09:20:00Z</td>\n",
              "      <td>-1.070284</td>\n",
              "      <td>-0.579430</td>\n",
              "      <td>-0.285167</td>\n",
              "      <td>False</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2021-01-02T09:21:00Z</td>\n",
              "      <td>-0.498136</td>\n",
              "      <td>-0.263619</td>\n",
              "      <td>-1.521442</td>\n",
              "      <td>False</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2021-01-02T09:22:00Z</td>\n",
              "      <td>-0.378106</td>\n",
              "      <td>0.949444</td>\n",
              "      <td>0.578883</td>\n",
              "      <td>False</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2021-01-02T09:23:00Z</td>\n",
              "      <td>0.724273</td>\n",
              "      <td>1.211421</td>\n",
              "      <td>2.159496</td>\n",
              "      <td>True</td>\n",
              "      <td>0.305973</td>\n",
              "      <td>0.15597</td>\n",
              "      <td>0.250687</td>\n",
              "      <td>0.593343</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>996</th>\n",
              "      <td>2021-01-03T01:55:00Z</td>\n",
              "      <td>0.572729</td>\n",
              "      <td>-1.318392</td>\n",
              "      <td>0.492164</td>\n",
              "      <td>False</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>997</th>\n",
              "      <td>2021-01-03T01:56:00Z</td>\n",
              "      <td>1.311772</td>\n",
              "      <td>0.408282</td>\n",
              "      <td>0.278034</td>\n",
              "      <td>False</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>998</th>\n",
              "      <td>2021-01-03T01:57:00Z</td>\n",
              "      <td>1.079186</td>\n",
              "      <td>0.528480</td>\n",
              "      <td>0.066745</td>\n",
              "      <td>False</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>999</th>\n",
              "      <td>2021-01-03T01:58:00Z</td>\n",
              "      <td>0.138812</td>\n",
              "      <td>0.657773</td>\n",
              "      <td>-0.456893</td>\n",
              "      <td>False</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1000</th>\n",
              "      <td>2021-01-03T01:59:00Z</td>\n",
              "      <td>-0.967487</td>\n",
              "      <td>0.432951</td>\n",
              "      <td>-0.316755</td>\n",
              "      <td>False</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1001 rows × 9 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                 timestamp  sensor_1  sensor_2  ...  series_0  series_1  series_2\n",
              "0     2021-01-02T09:19:00Z -0.044257 -0.968458  ...   0.00000  0.000000  0.000000\n",
              "1     2021-01-02T09:20:00Z -1.070284 -0.579430  ...   0.00000  0.000000  0.000000\n",
              "2     2021-01-02T09:21:00Z -0.498136 -0.263619  ...   0.00000  0.000000  0.000000\n",
              "3     2021-01-02T09:22:00Z -0.378106  0.949444  ...   0.00000  0.000000  0.000000\n",
              "4     2021-01-02T09:23:00Z  0.724273  1.211421  ...   0.15597  0.250687  0.593343\n",
              "...                    ...       ...       ...  ...       ...       ...       ...\n",
              "996   2021-01-03T01:55:00Z  0.572729 -1.318392  ...   0.00000  0.000000  0.000000\n",
              "997   2021-01-03T01:56:00Z  1.311772  0.408282  ...   0.00000  0.000000  0.000000\n",
              "998   2021-01-03T01:57:00Z  1.079186  0.528480  ...   0.00000  0.000000  0.000000\n",
              "999   2021-01-03T01:58:00Z  0.138812  0.657773  ...   0.00000  0.000000  0.000000\n",
              "1000  2021-01-03T01:59:00Z -0.967487  0.432951  ...   0.00000  0.000000  0.000000\n",
              "\n",
              "[1001 rows x 9 columns]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "rdf = (result.select(\"timestamp\",*inputColumns, \"results.contributors\", \"results.isAnomaly\", \"results.severity\")\n",
        "    .orderBy('timestamp', ascending=True)\n",
        "    .filter(col('timestamp') >= lit(startInferenceTime))\n",
        "    .toPandas())\n",
        "\n",
        "def parse(x):\n",
        "    if type(x) is list:\n",
        "        return dict([item[::-1] for item in x])\n",
        "    else:\n",
        "        return {'series_0': 0, 'series_1': 0, 'series_2': 0}\n",
        "\n",
        "rdf['contributors'] = rdf['contributors'].apply(parse)\n",
        "rdf = pd.concat([rdf.drop(['contributors'], axis=1), pd.json_normalize(rdf['contributors'])], axis=1)\n",
        "rdf"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "# 👀Visualisation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "minSeverity = 0.1\n",
        "\n",
        "\n",
        "####### Main Figure #######\n",
        "plt.figure(figsize=(23,8))\n",
        "plt.plot(rdf['timestamp'],rdf['sensor_1'], color='tab:orange', linestyle='solid', linewidth=2, label='sensor_1')\n",
        "plt.plot(rdf['timestamp'],rdf['sensor_2'], color='tab:green', linestyle='solid', linewidth=2, label='sensor_2')\n",
        "plt.plot(rdf['timestamp'],rdf['sensor_3'], color='tab:blue', linestyle='solid', linewidth=2, label='sensor_3')\n",
        "plt.grid(axis='y')\n",
        "plt.tick_params(axis='x',which='both',bottom=False,labelbottom=False)\n",
        "plt.legend()\n",
        "\n",
        "anoms = list(rdf[\"severity\"] >= minSeverity)\n",
        "_, _, ymin, ymax = plt.axis()\n",
        "plt.vlines(np.where(anoms), ymin=ymin , ymax=ymax , color='r', alpha=0.8)\n",
        "\n",
        "plt.legend()\n",
        "plt.title('A plot of the values from the three sensors with the detected anomalies highlighted in red.')\n",
        "plt.show()\n",
        "\n",
        "####### Severity Figure #######\n",
        "plt.figure(figsize=(23,1))\n",
        "plt.tick_params(axis='x',which='both',bottom=False,labelbottom=False)\n",
        "plt.plot(rdf['timestamp'],rdf['severity'], color='black', linestyle='solid', linewidth=2, label='Severity score')\n",
        "plt.plot(rdf['timestamp'],[minSeverity]*len(rdf['severity']), color='red', linestyle='dotted', linewidth=1, label='minSeverity')\n",
        "plt.grid(axis='y')\n",
        "plt.legend()\n",
        "plt.ylim([0,1])\n",
        "plt.title(\"Severity of the detected anomalies\")\n",
        "plt.show()\n",
        "\n",
        "####### Contributors Figure #######\n",
        "plt.figure(figsize=(23,1))\n",
        "plt.tick_params(axis='x',which='both',bottom=False,labelbottom=False)\n",
        "plt.bar(rdf['timestamp'],rdf['series_0'], width=2, color='tab:orange', label='sensor_1')\n",
        "plt.bar(rdf['timestamp'],rdf['series_1'], width=2, color='tab:green', label='sensor_2', bottom=rdf['series_0'])\n",
        "plt.bar(rdf['timestamp'],rdf['series_2'], width=2, color='tab:blue', label='sensor_3', bottom=rdf['series_0']+rdf['series_1'])\n",
        "plt.grid(axis='y')\n",
        "plt.legend()\n",
        "plt.ylim([0,1])\n",
        "plt.title(\"The contribution of each sensor to the detected anomaly\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "![image-alt-text](https://camo.githubusercontent.com/3917917017cbfcb6b4c062866d6824bbbf264ec46bbd096a2a624e4fc6f98433/68747470733a2f2f6d6d6c737061726b2e626c6f622e636f72652e77696e646f77732e6e65742f67726170686963732f6d7661645f706c6f742e706e67)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "For further questions on this tutorial, feel free to contact:\n",
        "\n",
        "Louise Han | Program Manager of Anomaly Detector | jingruhan@microsoft.com\n",
        "\n",
        "Mark Hamilton | Software Engineer of Synapse | marhamil@microsoft.com"
      ]
    }
  ],
  "metadata": {
    "description": null,
    "kernelspec": {
      "display_name": "Synapse PySpark",
      "name": "synapse_pyspark"
    },
    "language_info": {
      "name": "python"
    },
    "save_output": true,
    "synapse_widget": {
      "state": {},
      "version": "0.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
